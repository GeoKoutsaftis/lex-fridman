{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c389aeaf-8cb3-40b9-82bc-17a19aba0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone\n",
      "  Using cached pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from pinecone) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from pinecone) (1.8.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from pinecone) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from pinecone) (2.2.3)\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gr-pi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
      "Using cached pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
      "Installing collected packages: pinecone\n",
      "Successfully installed pinecone-7.3.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install --upgrade pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b37f370-b8a2-447f-a639-abf6f2d66d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Pinecone index: lex-fridman-podcast\n",
      "✅ Embedding model loaded!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "PINECONE_API_KEY = \"pcsk_62Uxwz_LAxDEHVVWcTNuXtydxfnnZqq2z1DpwyXdYY2LKSByaod6aAGxNghEiWyc7nHt98"  \n",
    "INDEX_NAME = \"lex-fridman-podcast\"\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "LLM_MODEL = \"mistral\"  \n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Check if index exists\n",
    "indexes = [i.name for i in pc.list_indexes()]\n",
    "if INDEX_NAME not in indexes:\n",
    "    print(f\"❌ Index '{INDEX_NAME}' not found. Please create it in Pinecone (dim=384, metric=cosine).\")\n",
    "else:\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    print(f\"✅ Connected to Pinecone index: {INDEX_NAME}\")\n",
    "\n",
    "# Load embedding model\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "print(\"✅ Embedding model loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a174581-b720-41fd-8116-0a6dd02c5d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Retrieval function ready!\n"
     ]
    }
   ],
   "source": [
    "def retrieve_context(query, top_k=3):\n",
    "    \"\"\"Retrieve relevant text chunks from Pinecone.\"\"\"\n",
    "    q_emb = embedder.encode([query])[0].tolist()\n",
    "    results = index.query(vector=q_emb, top_k=top_k, include_metadata=True)\n",
    "    context = \"\\n\".join([m[\"metadata\"][\"text\"] for m in results[\"matches\"]])\n",
    "    return context\n",
    "\n",
    "print(\"✅ Retrieval function ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0d2d96-50f6-4e1a-af31-e7f2ae38c3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ollama query function ready!\n"
     ]
    }
   ],
   "source": [
    "def query_ollama(model, prompt):\n",
    "    \"\"\"Query a local LLM via Ollama.\"\"\"\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json().get(\"response\", \"\")\n",
    "\n",
    "print(\"✅ Ollama query function ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d6770a-99da-4f32-9b2e-d171a88b29e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Answer generation ready!\n"
     ]
    }
   ],
   "source": [
    "def generate_answer(query):\n",
    "    \"\"\"Generate an answer using context + local LLM.\"\"\"\n",
    "    context = retrieve_context(query)\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant answering questions about the Lex Fridman Podcast.\n",
    "    Use ONLY the following context to answer the question.\n",
    "    If the answer isn't in the context, say \"I don't know.\"\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {query}\n",
    "    \"\"\"\n",
    "    return query_ollama(LLM_MODEL, prompt)\n",
    "\n",
    "print(\"✅ Answer generation ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccade8c-008a-4eb5-858c-8fc49ef89147",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    q = input(\"\\nAsk a question (or 'quit'): \")\n",
    "    if q.lower() == \"quit\":\n",
    "        break\n",
    "    answer = generate_answer(q)\n",
    "    print(f\"\\nAnswer: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab37c0d-41e8-4feb-91ae-d3dd8e079d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRANSCRIPT_PATH = \"podcastdata_dataset.csv\"  \n",
    "\n",
    "df = pd.read_csv(TRANSCRIPT_PATH)\n",
    "texts = df['text'].dropna().tolist()\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, overlap=200):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(len(text), start + chunk_size)\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "all_chunks = []\n",
    "for text in texts:\n",
    "    all_chunks.extend(chunk_text(text))\n",
    "\n",
    "print(f\"✅ Created {len(all_chunks)} chunks from transcript!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188bc814-aadc-4750-a0f1-32c9a64778c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from uuid import uuid4\n",
    "\n",
    "def upload_chunks(chunks):\n",
    "    vectors = []\n",
    "    for chunk in tqdm(chunks, desc=\"Embedding\"):\n",
    "        emb = embedder.encode([chunk])[0].tolist()\n",
    "        vectors.append({\n",
    "            \"id\": str(uuid4()),\n",
    "            \"values\": emb,\n",
    "            \"metadata\": {\"text\": chunk}\n",
    "        })\n",
    "    index.upsert(vectors)\n",
    "    print(f\"✅ Uploaded {len(vectors)} vectors to Pinecone!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c680ee9-a84c-451b-b8d4-c560984817f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query, top_k=3):\n",
    "    q_emb = embedder.encode([query])[0].tolist()\n",
    "    results = index.query(vector=q_emb, top_k=top_k, include_metadata=True)\n",
    "    return \"\\n\".join([m[\"metadata\"][\"text\"] for m in results[\"matches\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de92305-c771-46d2-bfe9-f5836d8c4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ollama(model, prompt):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json().get(\"response\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a6665-2a18-49b9-85e6-46efe5dbb42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    context = retrieve_context(query)\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant answering questions about the Lex Fridman Podcast.\n",
    "    Use ONLY the following context to answer the question.\n",
    "    If the answer isn't in the context, say \"I don't know.\"\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {query}\n",
    "    \"\"\"\n",
    "    return query_ollama(LLM_MODEL, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c480f-9670-482a-8345-7531fc693fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    q = input(\"\\nAsk a question (or 'quit'): \")\n",
    "    if q.lower() == \"quit\":\n",
    "        break\n",
    "    answer = generate_answer(q)\n",
    "    print(f\"\\nAnswer: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cd649-b33b-44d7-a9a6-f80b698bd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


# https://lex-fridman-4gqh39j66uspe8q76rvfzr.streamlit.app/
